# Token

## Die einfache Analogie

Tokens sind wie **Puzzleteile**, die KI verwendet, um Text zu verarbeiten. Genau wie Sie ein komplexes Puzzle in handhabbare Teile zerbrechen k√∂nnten, zerlegt die KI Ihren Text in Chunks namens Tokens.

Denken Sie daran als die "Leseeinheiten" der KI - nicht immer ganze W√∂rter, aber bedeutungsvolle Chunks, die die KI verstehen und verarbeiten kann.

## Wie W√∂rter zu Tokens werden

### Einfache Beispiele

**Kurze/h√§ufige W√∂rter** = 1 Token jeweils:
- "der" = 1 Token
- "und" = 1 Token  
- "Katze" = 1 Token

**L√§ngere W√∂rter** k√∂nnten 1 Token sein:
- "Elefant" = 1 Token
- "wunderbar" = 1 Token

**Komplexe/ungew√∂hnliche W√∂rter** werden zerlegt:
- "Anthropomorphismus" = 2 Tokens: "Anthrop" + "omorphismus"
- "Telekommunikation" = 3 Tokens: "Tele" + "kommun" + "ikation"

**Zahlen und Satzzeichen**:
- "123" = 1 Token
- "1.234.567" = 4 Tokens: "1" + "." + "234" + "." + "567"
- "!!!" = 3 Tokens: "!" + "!" + "!"

### Aufschl√ºsselung eines echten Beispiels

**Text**: "Hallo! Wie geht es dir heute?"

**Tokens**: 
1. "Hallo"
2. "!"
3. "Wie"
4. "geht" 
5. "es"
6. "dir"
7. "heute"
8. "?"

**Gesamt**: 8 Tokens

## Warum Tokens f√ºr Ihre Arbeit wichtig sind

### 1. Kostenauswirkung üí∞

KI-Services berechnen nach Tokens:
- **Input-Tokens**: Was Sie senden (Ihr Prompt)
- **Output-Tokens**: Was die KI zur√ºcksendet (die Antwort)

**Beispiel-Kostenberechnung**:
```
Ihr Prompt: 100 Tokens
KI-Antwort: 300 Tokens
Gesamt: 400 Tokens berechnet

Wenn das Modell $0,002 pro 1.000 Tokens kostet:
Ihre Kosten = 400 √ó $0,002 √∑ 1.000 = $0,0008 (weniger als ein Cent)
```

### 2. L√§ngenbeschr√§nkungen üìè

Jedes Modell hat ein **Kontextfenster** - maximale Tokens, die es verarbeiten kann:

| Modell | Kontextfenster | Entsprechende Seiten |
|-------|----------------|------------------|
| GPT-3.5 | 4.000 Tokens | ~3 Seiten |
| GPT-4 | 8.000-32.000 Tokens | ~6-25 Seiten |
| Claude 3 | 200.000 Tokens | ~150 Seiten |

**Was passiert, wenn Sie das Limit √ºberschreiten?**
- KI "vergisst" fr√ºhere Teile langer Gespr√§che
- Gro√üe Dokumente werden abgeschnitten
- Komplexe Aufgaben k√∂nnen nicht abgeschlossen werden

### 3. Leistungsauswirkung ‚ö°

Mehr Tokens = langsamere Antwortzeit und h√∂here Kosten
- Halten Sie Prompts pr√§gnant aber klar
- Teilen Sie gro√üe Aufgaben in kleinere Chunks auf
- Verwenden Sie angemessene Modelle f√ºr die Dokumentgr√∂√üe

## Praktische B√ºrostrategien

### Effiziente Prompts schreiben

**Ineffizient** (verschwendet Tokens):
```
"Ich w√ºrde es sehr sch√§tzen, wenn Sie mir bitte beim Schreiben einer E-Mail an unseren Kunden bez√ºglich der Besprechung helfen k√∂nnten, die wir f√ºr n√§chsten Dienstag geplant hatten, und ich muss sie auf Donnerstag verschieben, und ich m√∂chte sicherstellen, dass der Ton professionell und entschuldigend ist."
```
*Token-Anzahl: ~55*

**Effizient** (spart Tokens):
```
"Schreiben Sie eine professionelle, entschuldigende E-Mail, die die Dienstag-Kundenbesprechung auf Donnerstag verschiebt."
```
*Token-Anzahl: ~18*

### Lange Dokumente verwalten

**Problem**: 50-seitiger Bericht √ºberschreitet Token-Limit

**L√∂sungen**:
1. **Aufteilen**: 10 Seiten auf einmal analysieren
2. **Erst zusammenfassen**: KI eine Zusammenfassung erstellen lassen, dann detaillierte Fragen stellen
3. **Schl√ºsselabschnitte extrahieren**: Fokus auf spezifische Kapitel/Abschnitte
4. **Hochkapazit√§tsmodelle verwenden**: Claude 3 f√ºr sehr lange Dokumente

### Token-Sch√§tztipps

**Schnelle Sch√§tzung**:
- **1 Token ‚âà 4 Zeichen** (einschlie√ülich Leerzeichen)
- **1 Token ‚âà 0,75 W√∂rter** im Durchschnitt
- **100 W√∂rter ‚âà 130-150 Tokens**

**Tools zur exakten Z√§hlung**:
- OpenAIs Tokenizer-Tool
- Zeichen-/Wortzahl √∑ 4 (grobe Sch√§tzung)

## H√§ufige Token-bezogene Probleme

### "Gespr√§ch zu lang"-Fehler
**Problem**: Multi-Turn-Gespr√§ch √ºberschreitet Kontextfenster
**L√∂sung**: Neues Gespr√§ch beginnen oder vorherige Diskussion zusammenfassen

### "Unvollst√§ndige Antwort" 
**Problem**: KI h√∂rt mitten im Satz auf
**L√∂sung**: KI bitten fortzufahren, oder Anfrage in kleinere Teile aufteilen

### Hohe unerwartete Kosten
**Problem**: Rechnungen sind h√∂her als erwartet
**L√∂sung**: Token-Nutzung √ºberwachen, einfachere Modelle f√ºr einfache Aufgaben verwenden

## Geld sparende Token-Tipps

1. **Seien Sie pr√§gnant**: Unn√∂tige W√∂rter aus Prompts entfernen
2. **Beispiele sparsam verwenden**: Jedes Beispiel f√ºgt Tokens hinzu
3. **Richtiges Modell w√§hlen**: GPT-4 nicht f√ºr einfache Aufgaben verwenden
4. **Kontext wiederverwenden**: Auf vorherigen Antworten aufbauen statt Kontext zu wiederholen
5. **√Ñhnliche Anfragen b√ºndeln**: Mehrere √§hnliche Aufgaben in einem Prompt bearbeiten

## Schl√ºsselerkenntnis

Tokens sind die **W√§hrung** der KI-Interaktion:
- Sie bestimmen Ihre Kosten
- Sie begrenzen, wie viel Sie auf einmal verarbeiten k√∂nnen
- Sie beeinflussen die Antwortgeschwindigkeit

Denken Sie an Tokens wie **Textdatenverbrauch** - seien Sie achtsam, aber obsessieren Sie nicht √ºber jeden einzelnen Token.

---

**Weiter**: Meistern Sie die Kunst des [Prompting](./04-prompt.md), um bessere KI-Antworten zu erhalten.